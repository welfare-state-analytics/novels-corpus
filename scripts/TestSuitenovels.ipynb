{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files exist without duplicates, and there are equally many ID's in the metadata.csv with no duplicates!\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "def unittest_unique():\n",
    "    pathfiles = pathlib.Path(\"../corpus/novels\")\n",
    "    pathexel = pathlib.Path(\"../corpus/metadata/meta_data.xlsx\")\n",
    "    novel_paths = [x for x in pathfiles.iterdir()]\n",
    "    df = pd.read_excel(pathexel, index_col=False)\n",
    "    meta_data_ids=df['Datalab ID'].values\n",
    "    if len(set(novel_paths)) == len(novel_paths) == len(set(meta_data_ids)) == len(meta_data_ids) == 2951:\n",
    "        print(f\"All files exist without duplicates, and there are equally many ID's in the metadata file with no duplicates!\")\n",
    "    else:\n",
    "        print(f\"There are {len(set(novel_paths))} unique files, and there are {len(set(meta_data_ids))} unique ID's in the metadata file\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ID's of all files exist in the metadata.csv!\n"
     ]
    }
   ],
   "source": [
    "def unittest_metadata():\n",
    "    pathfiles = pathlib.Path(\"../corpus/novels\")\n",
    "    pathcsv = pathlib.Path(\"../corpus/metadata/meta_data.xlsx\")\n",
    "    blm_paths = [x for x in pathfiles.iterdir()]\n",
    "    success=True\n",
    "    df = pd.read_csv(pathcsv, index_col=False)\n",
    "    meta_data_ids=df['Datalab ID'].values\n",
    "    for id in blm_paths:\n",
    "        if id.name in meta_data_ids:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"The file with ID {id.name} does not exist in the metadata.csv\")\n",
    "            success=False\n",
    "            break\n",
    "    if success:\n",
    "        print(\"The ID's of all files exist in the metadata.csv!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emillanzen/.local/lib/python3.8/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files passed!\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from ebooklib import epub\n",
    "\n",
    "def unittest_epub():\n",
    "    path = pathlib.Path(\"../corpus/novels\")\n",
    "    novels = [x for x in path.iterdir()]\n",
    "    for x in novels:\n",
    "        epub_name = x.name.replace(\"blm\", \"epub\")\n",
    "        epub_path = pathlib.Path(\"unittest_epub\") / epub_name\n",
    "        success = True\n",
    "        if not epub_path.parent.exists():\n",
    "            epub_path.parent.mkdir()\n",
    "        try:\n",
    "            shutil.make_archive(str(epub_path), 'zip', str(x))\n",
    "            epub_zip_path = pathlib.Path(str(epub_path) + \".zip\")\n",
    "            epub_zip_path.rename(epub_path)\n",
    "            epub.read_epub(epub_path)\n",
    "            epub_path.unlink()\n",
    "        except:\n",
    "            print(f\"An error has occurred with ID {x.name}\")\n",
    "            success = False\n",
    "            break\n",
    "    if success:\n",
    "        print(\"All files passed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest_epub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files have at least one alto_xlm file\n"
     ]
    }
   ],
   "source": [
    "import kblab\n",
    "from kblab import Archive\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "def unittest_altoxml():\n",
    "    blm={\"label\": \"BONNIERS\", \"tags\": \"issue\"}\n",
    "    max_number = 1000\n",
    "    ids = []\n",
    "    with open('/home/emillanzen/Documents/pw.txt', 'r') as file:\n",
    "        pw = file.read().replace('\\n', '')\n",
    "    a = Archive(\"https://datalab.kb.se\", auth=(\"demo\", pw))\n",
    "    for package_id in a.search(blm, max=max_number):\n",
    "        ids.append(package_id)\n",
    "    success = True\n",
    "    for id in ids:\n",
    "        page = requests.get(f\"https://datalab.kb.se/{id}/_view\", auth=HTTPBasicAuth(\"demo\", pw), stream=True)\n",
    "        if page.content.find(b'application/xml') != -1:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"An alto_xml file does not exist for edition with ID {id}.\")\n",
    "            success = False\n",
    "            break\n",
    "    if success:\n",
    "        print(\"All files have at least one alto_xlm file.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest_altoxml()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
