{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kblab import Archive\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from ebooklib import epub\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "seed = 12345\n",
    "\n",
    "romaner=[{\"meta.host_title\": \"Welfare state analytics\"},\"https://datalab.kb.se\"]\n",
    "blm=[{\"label\": \"BONNIERS\", \"tags\": \"issue\"},\"https://datalab.kb.se\"]\n",
    "dn=[{\"tags\": \"issue\"},\"https://betalab.kb.se\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(filter=blm,max_number=1):\n",
    "    \"\"\"API call to obtain a list of all books from kblab. \n",
    "    Args:\n",
    "        filter (dictionary): A dictionary containing the filters for the packages in the betalab query.\n",
    "        max_number (int): An integer specifying the highest number of packages to query.\n",
    "    Returns:\n",
    "        books (list): a list containing a list of responses from requests.get, containing alto-xml files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate random number by seed for the the UUid\n",
    "    rd = random.Random()\n",
    "    rd.seed(seed)\n",
    "\n",
    "\n",
    "    home_dir=str(Path.home())\n",
    "    with open(f'{home_dir}/Documents/pw.txt', 'r') as file:\n",
    "        pw = file.read().replace('\\n', '')\n",
    "\n",
    "    a = Archive(filter[1], auth=(\"demo\", pw))\n",
    "    books=[]\n",
    "    xmlns='http://www.loc.gov/standards/alto/ns-v2#'\n",
    "    for package_id in a.search(filter[0], max=max_number):\n",
    "        write_root=etree.Element(package_id)\n",
    "        page_index=1\n",
    "        for x in a.get(package_id):\n",
    "            if \"alto.xml\" in x:\n",
    "                for i in range(5):\n",
    "                    backoff_time = 0.1 * (2 ** i)\n",
    "                    page=requests.get(f\"{filter[1]}/{package_id}/{x}\", auth=HTTPBasicAuth(\"demo\", pw),stream=True)\n",
    "                    if page.status_code == 200:\n",
    "                        tree= ET.ElementTree(ET.fromstring(page.text))\n",
    "                        \"\"\" Extract text content from ALTO xml file \"\"\"\n",
    "                        page_jp = f\"{filter[1]}/{package_id}/{x[:-9]}.jp2/_view\"\n",
    "                        pb=etree.SubElement(write_root, \"pb\")\n",
    "                        pb.set(\"n\",f\"{page_index}\")\n",
    "                        pb.set(\"uuid\",str(uuid.UUID(int=rd.getrandbits(128))))\n",
    "                        pb.set(\"facs\",f\"{page_jp}\")\n",
    "                        #contentinpage set here\n",
    "\n",
    "                        # Check if the page has no text\n",
    "                        if not tree.find('.//{%s}TextLine' % xmlns):\n",
    "                            picture_page = etree.SubElement(write_root, \"Image\")\n",
    "                            picture_page.text = f\"IMAGE PAGE, link to the page: {page_jp}\"\n",
    "\n",
    "                        # Find all <TextLine> elements\n",
    "                        for lines in tree.iterfind('.//{%s}TextLine' % xmlns):\n",
    "                            # New line after every <TextLine> element\n",
    "                            # Find all <String> elements\n",
    "                            block=[]\n",
    "\n",
    "                            for line in lines.findall('{%s}String' % xmlns):\n",
    "                                # Check if there are no hyphenated words\n",
    "                                if ('SUBS_CONTENT' not in line.attrib and 'SUBS_TYPE' not in line.attrib):\n",
    "                                    style=line.attrib.get('STYLEREFS')\n",
    "                                    block.append( line.attrib.get('CONTENT') )\n",
    "                                else:\n",
    "                                    block.append( line.attrib.get('SUBS_CONTENT') )\n",
    "\n",
    "                            block=\" \".join(block)\n",
    "\n",
    "                            if block!=\" \" and block!=\"\":\n",
    "                                if \"<\" in block or \">\" in block:\n",
    "                                    block=block.replace(\"<\",\"\")\n",
    "                                    block=block.replace(\">\",\"\")\n",
    "                                content_in_page=etree.SubElement(pb, \"p\")\n",
    "                                content_in_page.text=block\n",
    "\n",
    "                        page_index+=1\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"{filter[1]}/{package_id}/{x} failed\")\n",
    "                        time.sleep(backoff_time)\n",
    "\n",
    "        books.append(etree.tostring(write_root, pretty_print=True))\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(filter=blm,max_number=1000):\n",
    "    \"\"\"function to return all ids\n",
    "    \"\"\"\n",
    "    home_dir=str(Path.home())\n",
    "    with open(f'{home_dir}/Documents/pw.txt', 'r') as file:\n",
    "        pw = file.read().replace('\\n', '')\n",
    "\n",
    "    a = Archive(filter[1], auth=(\"demo\", pw))\n",
    "    ids=[]\n",
    "    for package_id in a.search(filter[0], max=max_number):\n",
    "        ids.append(package_id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for content,id in zip(get_content(),get_ids()):\n",
    "        book = epub.EpubBook()\n",
    "\n",
    "        # set metadata\n",
    "\n",
    "        book = epub.EpubBook()\n",
    "\n",
    "        # set metadata\n",
    "        book.set_identifier(id)\n",
    "        book.set_title(\"Sample book\")\n",
    "        book.set_language(\"sv\")\n",
    "\n",
    "\n",
    "        # create content in one chapter\n",
    "        c1 = epub.EpubHtml(title=id, file_name=\"content.xhtml\", lang=\"sv\")\n",
    "        c1.content = content\n",
    "        book.add_item(c1)\n",
    "\n",
    "        # add default NCX and Nav file\n",
    "        book.add_item(epub.EpubNcx())\n",
    "        book.add_item(epub.EpubNav())\n",
    "\n",
    "        # define CSS style\n",
    "        style = \"BODY {color: white;}\"\n",
    "        nav_css = epub.EpubItem(\n",
    "            uid=\"style_nav\",\n",
    "            file_name=\"style/nav.css\",\n",
    "            media_type=\"text/css\",\n",
    "            content=style,\n",
    "        )\n",
    "\n",
    "        # add CSS file\n",
    "        book.add_item(nav_css)\n",
    "\n",
    "        # basic spine\n",
    "        book.spine = [\"nav\", c1]\n",
    "\n",
    "        # write to the file\n",
    "        epub.write_epub(f\"{id}.epub\", book)\n",
    "        newpath = f\"../corpus/editions/{id}\" \n",
    "        Path(newpath).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "        with zipfile.ZipFile(f\"{id}.epub\", 'r') as zip_ref:\n",
    "            zip_ref.extractall(newpath)\n",
    "        Path(f\"{id}.epub\").unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
